#!/usr/bin/env python
# coding: utf-8

# <h2 align="center"> Titanic Survival Prediction Case Study </h2>

#  Importing the necessary Libraries
# 

# In[1]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import tree
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier

from warnings import filterwarnings
filterwarnings('ignore')


# # Loading the required Dataset

# In[2]:


df = pd.read_csv('train.csv')
df.head()


# * **Target variable is Survived which is Binary Categorical**

# ### Checking shape of dataset

# In[3]:


df.shape


# ### Checking Null Values 

# In[4]:


df.isnull().sum()


# * As the total 891 rows , In 'Cabin' there are more than 70% data is missing , so it is irrelevant to fill it 
# * Drop  Cabin column

# In[5]:


df.pop('Cabin')


# In[6]:


df.shape


# ### Filling Missing Values

# In[7]:


df['Age'].plot.hist()


# * as Curve is Bell Shaped , so fill the missing values by Mean

# In[8]:


df['Age'].fillna(df['Age'].mean(), inplace= True)


# * Embarked column is categorical so calculating the mode and filling it 

# In[9]:


df["Embarked"].value_counts()


# * We observe that max people are from S-southampton so we fill all with S

# In[10]:


df["Embarked"].fillna(value='S',inplace=True)


# * Now checking missing values

# In[11]:


df.isnull().sum()


# * All missing values are filled now , 

# ## Droping Irrelevent columns 

# * As the name column contain different name and the survival is not relevant to names
# * passenger Id does not make any sense
# * Ticket number doesnt provide any relevant information whether they survived or not so drop it

# In[12]:


df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)


# In[13]:


df.head()


# *  Now data only conatin relevant columns

# In[14]:


df.info()


# ### Changing Text data to Categorical 
# 
# * Label Encoding it encode the value as per given instance
# - Eg- columns has 3 category C/S/Q--it will form label
#     suppose 0-C, 1-S, 2-Q

# In[15]:


from sklearn.preprocessing import LabelEncoder
lab = LabelEncoder()

df["Sex"] = lab.fit_transform(df["Sex"])
df["Embarked"] = lab.fit_transform(df["Embarked"])


# In[16]:


df.head()


# # EDA 

# * I am prefering Raw Data for EDA : (not cleaned data)

# In[17]:


eda =  pd.read_csv('train.csv')


# In[18]:


eda.head()


# ## Catplot

# In[19]:


sns.catplot(x ="Sex", hue ="Survived", kind ="count", data = eda)


# ### Inference:
# Just by observing the graph, it can be approximated that: 
# * The survival rate of men is around 20% and that of women is around 75%. 
# 
# Therefore, whether a passenger is a male or a female plays an important role in determining if one is going to survive.

# In[20]:


sns.catplot(x ='Embarked', hue ='Survived', kind ='count', col ='Pclass', data =eda) 


# ### Heatmap

# In[21]:


# Group the dataset by Pclass and Survived and then unstack them 

group = eda.groupby(['Pclass', 'Survived']) 
pclass_survived = group.size().unstack() 

# Heatmap - Color encoded 2D representation of data. 

sns.heatmap(pclass_survived, annot = True, fmt ="d") 


# ### Inference
# It helps in determining if higher-class passengers had more survival rate than the lower class ones or vice versa. 
# * Class 1 passengers have a higher survival chance compared to classes 2 and 3. 
# 
# It implies that Pclass contributes a lot to a passengerâ€™s survival rate.

# ## Spliting Data into Dependent Variable and Independent variable

# In[22]:


df.head()


# In[23]:


y = df.iloc[:,:1]
y.head()


# In[24]:


X = df.drop(["Survived"],axis=1)
X.head()


# # Train the model using Decision Tree

# In[25]:


model = tree.DecisionTreeClassifier(max_depth=14)


# In[26]:


model.fit(X,y)


# ### Predicting Score 

# In[27]:


model.score(X,y)


# ## Applying Random Forest 

# In[28]:


rf = RandomForestClassifier(n_estimators=1000, max_features=2, oob_score=True)


# In[29]:


rf.fit(X,y)


# ### Checking Score 

# In[30]:


rf.oob_score_


# ### Finding Most Relevent Column for predicting Person Survived or not

# In[31]:


a = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']
for feature,imp in zip(a, rf.feature_importances_):
    print(feature,"\t :",imp);


# ### Inference:
# * Pclass, Sex , Age, Fare have value more than 0.05 ie, They are Important feature and affect the prediction of Survived Persons

# In[32]:


df.head()


# ## Spliting Dataset according to Important Columns

# In[33]:


x = df[['Age', 'Sex', 'Fare','Pclass']]
x.head()


# In[34]:


y.head()


# ### Fitting Decision Tree

# In[35]:


model = tree.DecisionTreeClassifier(max_depth=8)
model.fit(x,y)


# ### Creating Tree

# In[36]:


from sklearn.tree import export_graphviz
from IPython.display import SVG
from graphviz import Source
from IPython.display import display 


# In[37]:


with open('dt2.dot','w') as f:
    f = tree.export_graphviz(model, feature_names=['Age', 'Sex', 'Fare','Pclass'], out_file=f);


# In[38]:


graph = Source(tree.export_graphviz(model, out_file=None, feature_names=['Age', 'Sex', 'Fare','Pclass'],
                                    class_names=['0','1'] , filled = True))
display(SVG(graph.pipe(format='svg')))


# ### Predicting Score

# In[39]:


model.score(x,y)


# ## Fitting Random Forest

# In[40]:


rf.fit(x,y)


# ### Accuracy Score 

# In[41]:


rf.oob_score_


# ## Conclusion: 
# * The Accuracy score increases while predicting on Important Columns than predicting on All Columns
# 
# <hr>

# ## Prediction on  Test DataSet

# In[42]:


test_data = pd.read_csv('test.csv')


# In[43]:


test_data.head()


# ## Cleaning test data

# In[44]:


test_data.isnull().sum()


# ### Droping Irrelevent columns 

# In[45]:


df2 = test_data.drop(['Name','PassengerId','Ticket','Cabin'],axis=1)


# In[46]:


df2.head()


# ### Filling Null Values 

# In[47]:


df2['Age'].fillna(df2['Age'].mean(), inplace=True)
df2['Fare'].fillna(df2['Fare'].mean(), inplace=True)


# ### Converting Text Variables

# In[48]:


le = LabelEncoder()

df2["Sex"] = le.fit_transform(df2["Sex"])
df2["Embarked"] = le.fit_transform(df2["Embarked"])


# In[49]:


df2.head()


# ## Prediction on Test DataSet

# In[50]:


imp = df2[['Age', 'Sex', 'Fare','Pclass']]
imp.head()


# In[51]:


y_pred = model.predict(imp)


# In[52]:


y_pred


# ### Stroting Result into DataFrame

# In[53]:


result = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': y_pred })


# In[54]:


result


# ### Converting Dataframe to CSV File

# In[55]:


result.to_csv('TitanicPrediction.csv', index=False)


# ### Loading predicted Output

# In[56]:


output = pd.read_csv('TitanicPrediction.csv')
output.head()


# In[ ]:




